{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:22:01.373324Z",
     "start_time": "2021-02-04T23:21:57.763618Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "%matplotlib qt\n",
    "\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import calendar as cl\n",
    "from scipy.stats import pearsonr, median_absolute_deviation as mad, chi2\n",
    "from math import exp\n",
    "import random\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from statsmodels.stats.stattools import medcouple as calc_skew\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors as NN, LocalOutlierFactor as LOF\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.covariance import MinCovDet\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split as tvt\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Notebook settings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    " \n",
    "# Silence chained warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "import logging\n",
    "loggers = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "for logger in loggers:\n",
    "    logger.setLevel(logging.CRITICAL)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:22:03.279729Z",
     "start_time": "2021-02-04T23:22:01.884950Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read insurance data\n",
    "ins = pd.read_csv('/Users/mfairb/Documents/MSA/AA503/Spring2/Fraud Analytics/Code/aggregated_policy_nolabel.csv')\n",
    "ins_l = pd.read_csv('/Users/mfairb/Documents/MSA/AA503/Spring2/Fraud Analytics/Code/aggregated_policy_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Benford's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:22:06.951899Z",
     "start_time": "2021-02-04T23:22:06.282483Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[benfordslaw] >Analyzing digit position: [1]\n",
      "[benfordslaw] >[chi2] Anomaly detected! P=0, Tstat=13510.2\n"
     ]
    }
   ],
   "source": [
    "from benfordslaw import benfordslaw\n",
    "\n",
    "# Initialize\n",
    "bl = benfordslaw(alpha=0.05)\n",
    "\n",
    "# Extract election information.\n",
    "X = ins['Reward_Amount'].values\n",
    "results = bl.fit(X)\n",
    "\n",
    "# Plot\n",
    "bl.plot(title='Benfords Law');\n",
    "\n",
    "# The chi-square test is a test of the null hypothesis that the data follows Benford's Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Scores & Robust Z-Scores\n",
    "Using Z-scores works well with symmetric distributions (particularly normal) (because means and std. devs work well with symmetric distributions). HOWEVER - since we're trying to detect outliers, it doesn't necessarily make sense to use Z-score since normal distributions are heavily influence by outliers. Instead, use Robust Z-Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:22:54.468945Z",
     "start_time": "2021-02-04T23:22:54.192911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start with distribution of variable\n",
    "ins = ins.rename(columns={'Coverage_Income_Ratio_Claim':'CIRC'})\n",
    "\n",
    "plt.hist(ins.CIRC)\n",
    "plt.title('CIRC')\n",
    "plt.show();\n",
    "\n",
    "# Plot Z-scores\n",
    "ins['Z_CIRC'] = abs((ins.CIRC - np.mean(ins.CIRC)) / np.std(ins.CIRC))\n",
    "plt.hist(ins.Z_CIRC)\n",
    "plt.title('CIRC Z-scores')\n",
    "plt.show();\n",
    "\n",
    "# Plot robust Z-scores\n",
    "ins['RZ_CIRC'] = abs((ins.CIRC - np.median(ins.CIRC)) / mad(ins.CIRC))\n",
    "plt.hist(ins.RZ_CIRC)\n",
    "plt.title('CIRC Robust Z-scores')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Box-Plots\n",
    "1.5*IQR rule work best for symmetric distributions and often reports large number of outliers when skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T18:35:53.926683Z",
     "start_time": "2021-01-23T18:35:53.818305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adjusted boxplot - No python capability for this\n",
    "# Standard box-plot\n",
    "plt.boxplot(ins.CIRC)\n",
    "plt.title('CIRC Boxplot')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multivariate Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Mahalanobis Distances\n",
    "Generalization of z-scores to multi-dimensional space. Essentially done by replacing the univariate mean with the multivariate mean and the standard deviation with the covariance matrix\n",
    "\n",
    "***NOTE***: I chose to use the MinCovDet function from sklearn.covariance to compute the minimum covariance determinant. This function is known to contain bugs and has significant shortcomings compared to the covMcd function from R's robustbase library. As far as I've researched, there is no better way to compute the MCD in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T06:08:19.953391Z",
     "start_time": "2021-01-29T06:08:15.627868Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to get eigen values from covariance matrix\n",
    "def get_eigens(cov):\n",
    "    eig_values, eig_vectors = np.linalg.eig(cov) \n",
    "    l1 = eig_values[0]\n",
    "    l2 = eig_values[1]\n",
    "    return l1, l2\n",
    "\n",
    "# Plot\n",
    "x = ins.Time_Between_CL_R\n",
    "y = ins.Cov_Limit_Claim/1000\n",
    "\n",
    "# Plot x & y\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Time Between Claim and Payment')\n",
    "plt.ylabel('Coverage Limit at Claim (Thousands $)')\n",
    "plt.title('Coverage Limit vs. Speed of Payment')\n",
    "ax = plt.gca()\n",
    "\n",
    "# Get covariance matrix and resulting eigen values\n",
    "cov = np.cov(x, y)\n",
    "l1, l2 = get_eigens(cov)\n",
    "\n",
    "# Calculate \n",
    "ppf = chi2.ppf(0.9999975, 2)\n",
    "w = 2*np.sqrt(l1*ppf)\n",
    "h = 2*np.sqrt(l2*ppf)\n",
    "ell = Ellipse(xy=(x.mean(), y.mean()),\n",
    "              width=w,\n",
    "              height=h,\n",
    "              edgecolor='b', fc='None', lw=2)\n",
    "\n",
    "ax.add_patch(ell)\n",
    "ax.set_xlim(min(x)-3, max(x)+1)\n",
    "ax.set_ylim(min(y)-100, max(y)+200);\n",
    "\n",
    "# Calculate robust version of Mahalanobis Distance\n",
    "rmd = pd.DataFrame()\n",
    "rmd['x'] = x\n",
    "rmd['y'] = y\n",
    "\n",
    "# Get covariance matrix and resulting eigen values\n",
    "cov = MinCovDet(random_state=0).fit(rmd)\n",
    "robust_cov = cov.covariance_\n",
    "rl1, rl2 = get_eigens(robust_cov)\n",
    "\n",
    "# Calculate\n",
    "robust_center = cov.location_\n",
    "ppf = chi2.ppf(0.9999975, 2)\n",
    "rw = 2*np.sqrt(rl1*ppf)\n",
    "rh = 2*np.sqrt(rl2*ppf)\n",
    "robust_ell = Ellipse(xy=(robust_center[0], robust_center[1]),\n",
    "             width=rw,\n",
    "             height=rh,\n",
    "             edgecolor='r', fc='None', lw=2)\n",
    "\n",
    "ax.add_patch(robust_ell);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### K-Nearest Neighbors\n",
    "Still can be bothered by outliers since std. mean and covariance matrix used<br>\n",
    "kNN is good at detecting global outliers but not great at detecting local outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T01:51:12.210400Z",
     "start_time": "2021-01-24T01:51:10.890811Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# KNN on Time Between Claim ratio and Coverage limit claim\n",
    "kdf = pd.DataFrame()\n",
    "kdf['TBCR'] = ins.Time_Between_CL_R\n",
    "kdf['CLC'] = ins.Cov_Limit_Claim/1000\n",
    "\n",
    "# Fit KNN\n",
    "knn = NN(n_neighbors=5)\n",
    "knn.fit(kdf)\n",
    "\n",
    "# Get KNN score\n",
    "distances, indices = knn.kneighbors()\n",
    "\n",
    "# Get average distance to k nearest neighbros\n",
    "kdf['distances'] = [listy.mean() for listy in distances]\n",
    "\n",
    "# Plot KNN score\n",
    "plt.scatter(kdf.TBCR, kdf.CLC, s=kdf.distances+0.01)\n",
    "plt.title('Coverage Limit vs. Speed of Payment')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Local Outlier Factor (LOF)\n",
    "Ratio of average density of the kNN of an obs. to the density of the observation. Density here is essentially how far you have to travel to get to the nearest point. LOF calculates how far away a given point is from the nearest point and how far the nearest 5 observations are from that point. An LOF > 1 implies more anamolous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T03:35:41.812233Z",
     "start_time": "2021-01-29T03:35:41.050652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create LOF df\n",
    "ldf = pd.DataFrame()\n",
    "ldf['TBCR'] = ins.Time_Between_CL_R\n",
    "ldf['CLC'] = ins.Cov_Limit_Claim/1000\n",
    "\n",
    "# Fit LOF\n",
    "lof = LOF(n_neighbors=5)\n",
    "\n",
    "# Create labels: 1 for inlier, -1 for outlier\n",
    "labels = lof.fit_predict(ldf)\n",
    "\n",
    "# Get Negative outlier scores: \"The higher, the more normal. \n",
    "# Inliers tend to have a LOF score close to 1 (negative_outlier_factor_ close to -1), \n",
    "# while outliers tend to have a larger LOF score\" -sklearn)\n",
    "nos = -lof.negative_outlier_factor_\n",
    "\n",
    "outlier_index = np.where(labels==-1)[0]\n",
    "outliers = ldf[ldf.index.isin(outlier_index)]\n",
    "inliers = ldf[~ldf.index.isin(outlier_index)]\n",
    "\n",
    "# Plot points colored by label\n",
    "plt.scatter(inliers.TBCR, inliers.CLC)\n",
    "plt.scatter(outliers.TBCR,outliers.CLC, color='r')\n",
    "plt.title('Coverage Limit vs. Speed of Payment: Colored')\n",
    "plt.show();\n",
    "\n",
    "# Would like to implement but some values are too large. There may very well be a \n",
    "# way around this but would need to research\n",
    "# Plot points with size-adjusted by LOF \n",
    "# plt.scatter(ldf.TBCR, ldf.CLC, s=nos)\n",
    "# plt.title('Coverage Limit vs. Speed of Payment: Size-Adjusted')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Isolation Forest\n",
    "Randomly split along an axis (pick a random axis and a random point) and split there. Then, split again within splits that were already made. The easier it is to split a point, the more likely it is to be anamolous. Then standardize count of splits since algo would be different every time run. This is a single tree. To make a forest, perform many times and take average score of many trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T03:39:23.635840Z",
     "start_time": "2021-01-24T03:39:13.503714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create df for Isolation Forest\n",
    "idf = pd.DataFrame()\n",
    "idf['TBCR'] = ins.Time_Between_CL_R\n",
    "idf['CLC'] = ins.Cov_Limit_Claim/1000\n",
    "\n",
    "# Fit Isolation Forest\n",
    "iso_100 = IsolationForest(random_state=273,\n",
    "                          n_estimators=100,\n",
    "                          max_samples=1000).fit(idf)\n",
    "iso_500 = IsolationForest(random_state=273,\n",
    "                          n_estimators=500,\n",
    "                          max_samples=5000).fit(idf)\n",
    "\n",
    "# Get anomaly scores on train\n",
    "iso_100_scores = -iso_100.score_samples(idf)\n",
    "iso_500_scores = -iso_100.score_samples(idf)\n",
    "\n",
    "# Predict labels on train\n",
    "iso_100_labels = iso_100.predict(idf)\n",
    "iso_500_labels = iso_500.predict(idf)\n",
    "\n",
    "# Put in df\n",
    "idf['iso_100_score'] = iso_100_scores\n",
    "idf['iso_500_score'] = iso_500_scores\n",
    "idf['iso_100_labels'] = iso_100_labels\n",
    "idf['iso_500_labels'] = iso_500_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T17:57:56.173212Z",
     "start_time": "2021-01-24T17:57:54.599541Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot anomaly scores\n",
    "plt.hist(iso_100_scores);\n",
    "plt.title('Coverage Limit vs. Speed of Payment')\n",
    "plt.show();\n",
    "plt.hist(iso_500_scores)\n",
    "plt.title('Coverage Limit vs. Speed of Payment')\n",
    "plt.show();\n",
    "\n",
    "# Plot labels\n",
    "plt.scatter(idf.TBCR, idf.CLC, c=iso_100_labels)\n",
    "plt.show();\n",
    "\n",
    "# Plot scores\n",
    "plt.scatter(idf.TBCR, idf.CLC, s=iso_100_scores)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T02:38:03.789674Z",
     "start_time": "2021-01-29T02:38:03.030829Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(iso_100_scores);\n",
    "plt.hist([exp(s) for s in iso_100_scores]);\n",
    "plt.hist(iso_100_scores**2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T03:20:00.989199Z",
     "start_time": "2021-01-29T03:20:00.871604Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by PC 1 = 0.9999\n",
      "Variance explained by PC 2 = 0.0001\n",
      "Variance explained by PC 3 = 0.0\n",
      "Variance explained by PC 4 = 0.0\n"
     ]
    }
   ],
   "source": [
    "# Keep a few columns\n",
    "df = ins[['Reward_Amount', 'Time_Between_CL_R', 'Time_Between_IN_CL', 'Med_Conditions']]\n",
    "df['Med_Conditions'] = [4 if m == '3+' else m for m in df.Med_Conditions] # Cleaning step for ease of PCA\n",
    "\n",
    "# Scale data\n",
    "df_scaled = StandardScaler().fit_transform(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pcs = pd.DataFrame(pca.fit_transform(df), columns=[f'PC{i}' for i in range(1, 5)])\n",
    "\n",
    "# View amount of variance explained\n",
    "i = 1\n",
    "for v in pca.explained_variance_ratio_:\n",
    "    print(f'Variance explained by PC {i} = {round(v, 4)}')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T03:40:28.211487Z",
     "start_time": "2021-01-29T03:40:28.137259Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Plot initialisation\n",
    "def plot_pcs(pcs, labels):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(pcs['PC1'], pcs['PC2'], pcs['PC3'], c=labels, cmap=\"Set2_r\", s=60)\n",
    "    plt.show();\n",
    "     \n",
    "    # label the axes\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "    ax.set_title(\"PCA on the iris data set\")\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-29T03:20:05.766238Z",
     "start_time": "2021-01-29T03:20:05.422565Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "scale = 8\n",
    "# Make data.\n",
    "X = np.arange(-scale, scale, 0.25)\n",
    "Y = np.arange(-scale, scale, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                   linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(0, 100)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# rotate the axes and update\n",
    "for angle in range(0, 360):\n",
    "   ax.view_init(30, 40)\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
