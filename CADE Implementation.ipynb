{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CADE Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A novel implementation of methedologies described in the following paper:\n",
    "<br>\n",
    "###### Classifier-Adjusted Density Estimation for Anomaly Detection and One-Class Classification: Lisa Friedland, Amanda Gentzel  and David Jensen\n",
    "###### https://pdfs.semanticscholar.org/e4e6/033069a8569ba16f64da3061538bcb90bec6.pdf\n",
    "<br>\n",
    "Briefly, the following steps will be performed:\n",
    "<br>\n",
    "<br>\n",
    "Step 1 - \"Duplicate\" current data set (using uniform versions of each variable)\n",
    "<br>\n",
    "Step 2 - Label all original data as 0. Label all duplicated data 1\n",
    "<br>\n",
    "Step 3 - Combine data sets\n",
    "<br>\n",
    "Step 4 - Train a classifier on combined set\n",
    "<br>\n",
    "Step 5 - Score original data with classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dfply import *\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "#import xgboost as xgb\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(\"/Users/mfairb/Documents/ML Projects/Project - HR Analytics/hr_analytics.csv\")\n",
    "\n",
    "# Preprocess data function\n",
    "def preprocess(df):\n",
    "    \n",
    "    df = df.dropna().copy()\n",
    "    \n",
    "    # Create X & y\n",
    "    X = df >> select(df.no_of_trainings, df.age, df.previous_year_rating, df.length_of_service, df.avg_training_score)\n",
    "    y = df >> select(df.is_promoted)\n",
    "    \n",
    "    return(X, y)\n",
    "\n",
    "# Preprocess data and split into train and test\n",
    "X, y = preprocess(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=273)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34062, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(14598, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete CADE Function"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step 1 - \"Duplicate\" current data set (using uniform versions of each variable)\n",
    "Step 2 - Label all original data as 0. Label all duplicated data 1\n",
    "Step 3 - Combine data sets\n",
    "Step 4 - Train a classifier on combined set\n",
    "Step 5 - Score original data with classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Func: uniform_transform(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create uniform version of features\n",
    "def uniform_transform(col):\n",
    "    \n",
    "    # Define col_length as length of the column\n",
    "    col_length = len(col) \n",
    "    \n",
    "    # If data type is integer, sample integer values uniformly between lower and upper limits\n",
    "    if all(isinstance(c, int) for c in col):\n",
    "        new_var = random.choices( range( min(col), max(col)+1 ), k = col_length )\n",
    "        \n",
    "    # Else if data type is float\n",
    "    elif all(isinstance(c, float) for c in col):\n",
    "        \n",
    "        # Check to see if data should be integer (all values are actually integer values just stored as float) and if so, sample integer values uniformly between lower and upper limits\n",
    "        if all(c.is_integer() for c in col): # Check to see if all can actually be integers\n",
    "            col = list(map(int, col)) # Convert to integer\n",
    "            new_var = random.choices( range( min(col), max(col)+1 ), k = col_length )\n",
    "            \n",
    "        # If actually a float, sample uniformly between lower and upper limits\n",
    "        else:\n",
    "            new_var = np.random.uniform( low = min(col), high = max(col), size = col_length )\n",
    "       \n",
    "    # Else if a character values, sample uniformly from available levels\n",
    "    elif all(isinstance(c, str) for c in col):\n",
    "        new_var = random.choices( np.unique(col), k = col_length )\n",
    "\n",
    "    \n",
    "    return(new_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Func: create_cade_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete CADE function - prepares X/y to be modeled\n",
    "def create_cade_sets(X, y):\n",
    "    \n",
    "    # Apply uniform transformation to all columns to create X_fake\n",
    "    X_fake = X.apply(lambda x: uniform_transform(x), axis = 0).copy()\n",
    "    \n",
    "    # Create 0/1 responses. The zeroes will be assigned to the real data. The ones to the fake data\n",
    "    zeros = np.zeros(X.shape[0])\n",
    "    ones = np.ones(X_fake.shape[0])\n",
    "    \n",
    "    # Combine data sets and response vars. This will create a df with actual data on top and fake data under it.\n",
    "    # This allows us to append the ones array after the zeros array to create the appropriate response\n",
    "    X_cade = X.append(X_fake)\n",
    "    y_cade = np.append(zeros, ones)\n",
    "    \n",
    "    return(X_cade, y_cade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Func: train_model(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit ML models\n",
    "def train_model(X_train, y_train, model):\n",
    "    \n",
    "    # Logistic regression\n",
    "    if model == \"log\":\n",
    "        \n",
    "        log = LogisticRegression() # Create model\n",
    "        log.fit(X_train,y_train) # Fit model\n",
    "        return(log)\n",
    "    \n",
    "    # Random Forest\n",
    "    elif model == \"rf\":    \n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=500)\n",
    "        rf.fit(X_train,y_train)\n",
    "        return(rf)\n",
    "    \n",
    "    # XGBoost\n",
    "    elif model == \"xgb\":\n",
    "        \n",
    "        xgb_mod = xgb.XGBClassifier(random_state=273,learning_rate=0.01)\n",
    "        xgb_mod.fit(X_train, y_train)\n",
    "        return(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Func: cade(df, n_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cade(X, y, X_test, model):\n",
    "    \n",
    "    # Create rf classifier and fit on X_cade and y_cade dfs\n",
    "    model = train_model(X, y, model = model)\n",
    "    \n",
    "    # Predict probabilities on test set using above model\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    X_test['probs'] = pd.DataFrame(model.predict_proba(X_test)).iloc[:,1]\n",
    "\n",
    "    return(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cade sets\n",
    "X_cade, y_cade = create_cade_sets(X_train, y_train)\n",
    "\n",
    "# Perform CADE - return test set with predicted probabilities\n",
    "ins_cade = cade(X = X_cade, y = y_cade, X_test = X_train, model = 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31535</th>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23797</th>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21559</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>0.999959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16271</th>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>0.999882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>0.999845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28516</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.007433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33340</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.007342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21849</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.007342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27022</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.007342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30684</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0.007245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34062 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_trainings  age  previous_year_rating  length_of_service  \\\n",
       "31535               10   42                   3.0                 13   \n",
       "23797               10   36                   1.0                 10   \n",
       "21559               10   28                   3.0                  2   \n",
       "16271                9   27                   3.0                  4   \n",
       "8756                 9   26                   3.0                  3   \n",
       "...                ...  ...                   ...                ...   \n",
       "28516                1   28                   5.0                  1   \n",
       "33340                1   27                   5.0                  1   \n",
       "21849                1   27                   5.0                  1   \n",
       "27022                1   27                   5.0                  1   \n",
       "30684                1   24                   5.0                  1   \n",
       "\n",
       "       avg_training_score     probs  \n",
       "31535                  49  0.999994  \n",
       "23797                  66  0.999994  \n",
       "21559                  71  0.999959  \n",
       "16271                  75  0.999882  \n",
       "8756                   73  0.999845  \n",
       "...                   ...       ...  \n",
       "28516                  48  0.007433  \n",
       "33340                  48  0.007342  \n",
       "21849                  48  0.007342  \n",
       "27022                  48  0.007342  \n",
       "30684                  49  0.007245  \n",
       "\n",
       "[34062 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_cade >> arrange('probs', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
