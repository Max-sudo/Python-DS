{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A novel implementation of methodologies described in the following paper:\n",
    "<br>\n",
    "###### The Utility of Clustering in Prediction Tasks: Shubhendu Trivedi, Zachary A. Pardos and Neil T. Heffernan\n",
    "###### https://ttic.uchicago.edu/~shubhendu/Papers/clustering_bagging.pdf\n",
    "<br>\n",
    "Briefly, the following steps will be performed:\n",
    "<br>\n",
    "<br>\n",
    "1) Create sample with c designated clusters\n",
    "<br>\n",
    "2) Perform kmeans clustering for k ∈ {1, 2, ..., K}\n",
    "<br>\n",
    "3) For each cluster set, fit k models (one model for each cluster), ultimately creating a \"cluster model\"\n",
    "<br>\n",
    "4) Obtain predictions for a test set for the K cluster models\n",
    "<br>\n",
    "5) Ensemble predictions for final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1) Load and preprocess HR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:02:33.647821Z",
     "start_time": "2021-02-03T22:02:28.232929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employee_id           0\n",
       "no_of_trainings       0\n",
       "age                   0\n",
       "length_of_service     0\n",
       "KPIs_met >80%         0\n",
       "awards_won?           0\n",
       "avg_training_score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dfply import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas_profiling import profile_report\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import reduce\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Import data\n",
    "hr = pd.read_csv(\"/Users/mfairb/Documents/ML Projects/Project - HR Analytics/hr_analytics.csv\")\n",
    "\n",
    "# Keep numeric only for simplicity, reorder, drop 'employee_id'\n",
    "X = hr._get_numeric_data() >> drop(X.is_promoted, X.previous_year_rating)\n",
    "y = hr['is_promoted']\n",
    "\n",
    "# Scale predictors\n",
    "scaler = StandardScaler()\n",
    "col_names = list(X.columns)\n",
    "col_names.remove('employee_id')\n",
    "X[col_names] = scaler.fit_transform(X[col_names])\n",
    "\n",
    "# Create train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Check for null values\n",
    "X_train.apply( lambda x: sum( x.isnull() ) )\n",
    "\n",
    "# View X_train\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2) Perform kmeans clustering for k ∈ {1, 2, ..., K}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:24:02.294275Z",
     "start_time": "2021-02-03T22:24:00.609271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from numpy import unique, where\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create K models\n",
    "k_labels = pd.DataFrame()\n",
    "K = 8\n",
    "for i in range(1, K):\n",
    "    s_i = str(i)\n",
    "    exec(f'k{s_i} = KMeans(n_clusters = {s_i}, init = \"random\")') # Init. model\n",
    "    exec(f'k{s_i}.fit(X_train >> drop(X.employee_id, contains(\"k\")))') # Fit model\n",
    "    exec(f'k{s_i}_yhat = k{s_i}.predict(X_train >> drop(X.employee_id, contains(\"k\")))') # Get cluster labels\n",
    "    exec(f'X_train[\"k{s_i}\"] = k{s_i}_yhat') # Add to k_labels df\n",
    "    exec(f'k{s_i}_clusters = unique(k{s_i}_yhat)') # Get unique clusters\n",
    "    \n",
    "# cbind X_train and k_labels\n",
    "X_train = pd.concat([X_train.reset_index(drop=True), k_labels.reset_index(drop=True)], axis = 1)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all kmeans models and labels have been added to X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3) For each cluster set, fit k models (one model for each cluster), ultimately creating a \"cluster model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training sets and logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:26:06.531950Z",
     "start_time": "2021-02-03T22:26:06.044785Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "final_probs = pd.DataFrame()\n",
    "\n",
    "# Loop over K cluster sets\n",
    "for k in range(1, K):\n",
    "    \n",
    "    str_k = str(k)\n",
    "    \n",
    "    # Loop though individual clusters in the cluster set\n",
    "    for l in range(0, k):\n",
    "\n",
    "        # Convert indices to str for exec statements\n",
    "        str_l = str(l)\n",
    "        indices = str_k + str_l\n",
    "        X_indices = 'X' + indices\n",
    "        y_indices = 'y' + indices\n",
    "\n",
    "        # Create Xkl & ykl\n",
    "        exec(f'{X_indices}= X_train[X_train.k{str_k} == {str_l}]')\n",
    "        exec(f'{y_indices}= y_train[X_train.k{str_k} == {str_l}]')\n",
    "        \n",
    "        # Drop cluster label columns and employee_id\n",
    "        exec(f'{X_indices}={X_indices} >> drop(contains(\"k\"), X.employee_id)')\n",
    "        \n",
    "        # Fit logistic regression (logkl)\n",
    "        exec(f'log{indices} = LogisticRegression().fit({X_indices}, {y_indices})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all X_kl training sets and log_kl regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4) Get cluster lables and obtain predictions for a test set for the K cluster models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:33:13.406213Z",
     "start_time": "2021-02-03T22:33:13.091448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop over K cluster sest\n",
    "for k in range(1, K):\n",
    "    \n",
    "    str_k = str(k)\n",
    "    \n",
    "    # Create X_testk (to get all predictions)\n",
    "    exec(f'X_test{str_k} = pd.DataFrame()') # Create X_testk\n",
    "\n",
    "         \n",
    "    # Get cluster labels for X_test and add them to X_test (call it hold)\n",
    "    exec(f'labels = pd.DataFrame(k{str_k}.predict(X_test >> drop(X.employee_id)), columns = [\"label\"])')\n",
    "    hold = pd.concat([X_test.reset_index(drop = True), labels], axis = 1)\n",
    "         \n",
    "    # Loop over clusters in cluster set\n",
    "    for l in range(0, k):\n",
    "        \n",
    "       # Convert indices to str for exec statements\n",
    "        str_l = str(l)\n",
    "        indices = str_k + str_l\n",
    "        X_test_indices = 'X_test_' + indices\n",
    "        y_test_indices = 'y_test' + indices\n",
    "\n",
    "        # Create X_test\n",
    "        exec(f'{X_test_indices} = hold[hold.label == {str_l}]')\n",
    "        exec(f'{X_test_indices} = {X_test_indices}.reset_index(drop = True)')        \n",
    "        \n",
    "        # Get predictions from respective models and attach to employee_id\n",
    "        exec(f'{X_test_indices}[\"predicted_prob\"] = pd.Series(log{indices}.predict_proba({X_test_indices} >> drop(\"employee_id\", \"label\"))[:,1])')\n",
    "        \n",
    "        # Append to X_testi\n",
    "        exec(f'X_test{str_k} = X_test{str_k}.append({X_test_indices}) >> select(\"employee_id\", \"predicted_prob\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have predicted probabilities from all 7 cluster set models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5) Ensemble predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:34:20.564447Z",
     "start_time": "2021-02-03T22:34:19.917709Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Create list of dfs to merge\n",
    "tests = [X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7]\n",
    "\n",
    "# Merge using reduce(lambda...)) & change column names\n",
    "all_tests = reduce(lambda  left,right: pd.merge(left,right,on=['employee_id'],\n",
    "                                            how='left'), tests)\n",
    "all_tests.columns = ['employee_id', 'X_test1', 'X_test2', 'X_test3', 'X_test4', 'X_test5', 'X_test6', 'X_test7']\n",
    "\n",
    "# Calculate rowmeans\n",
    "all_tests['final_prediction'] = all_tests.drop('employee_id', axis=1).apply(lambda x: x.mean(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T22:34:22.966286Z",
     "start_time": "2021-02-03T22:34:22.911408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test1 AUC = 0.7962544209178521\n",
      "X_test2 AUC = 0.794527748413664\n",
      "X_test3 AUC = 0.8001164223698546\n",
      "X_test4 AUC = 0.8024241653783255\n",
      "X_test5 AUC = 0.8013704875969277\n",
      "X_test6 AUC = 0.8018165916231269\n",
      "X_test7 AUC = 0.8000985357382658\n",
      "Ensemble AUC = 0.8028421735083305\n"
     ]
    }
   ],
   "source": [
    "# Print AUC for each \n",
    "for i in range(1, 9):\n",
    "    if i != 8:\n",
    "        print('X_test' + str(i) + ' AUC = ' + str(roc_auc_score(y_test, all_tests.iloc[:,i])))\n",
    "    else:\n",
    "        print('Ensemble AUC = ' + str(roc_auc_score(y_test, all_tests.iloc[:,i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no tuning of individual or cluster models, our ensemble performs best with an AUC of 0.8028"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
